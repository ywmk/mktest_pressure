2025-09-08 21:46:00 - evalscope - INFO: Starting benchmark with args: 
2025-09-08 21:46:00 - evalscope - INFO: {
    "model": "Qwen2.5-0.5B-Instruct",
    "model_id": "Qwen2.5-0.5B-Instruct",
    "attn_implementation": null,
    "api": "openai",
    "tokenizer_path": "path",
    "port": 8877,
    "url": "http://127.0.0.1:8110/v1/chat/completions",
    "headers": {},
    "connect_timeout": 600,
    "read_timeout": 600,
    "api_key": null,
    "no_test_connection": false,
    "number": 10,
    "parallel": 1,
    "rate": -1,
    "sleep_interval": 5,
    "log_every_n_query": 10,
    "debug": false,
    "wandb_api_key": null,
    "swanlab_api_key": null,
    "name": null,
    "outputs_dir": "outputs/20250908_214600/Qwen2.5-0.5B-Instruct/parallel_1_number_10",
    "max_prompt_length": 512,
    "min_prompt_length": 128,
    "prefix_length": 0,
    "prompt": null,
    "query_template": null,
    "apply_chat_template": true,
    "image_width": 224,
    "image_height": 224,
    "image_format": "RGB",
    "image_num": 1,
    "dataset": "random",
    "dataset_path": null,
    "frequency_penalty": null,
    "repetition_penalty": null,
    "logprobs": null,
    "max_tokens": 512,
    "min_tokens": 512,
    "n_choices": null,
    "seed": 0,
    "stop": null,
    "stop_token_ids": null,
    "stream": true,
    "temperature": 0.0,
    "top_p": null,
    "top_k": null,
    "extra_args": {
        "ignore_eos": true
    }
}
2025-09-08 21:46:03 - evalscope - ERROR: Exception in async function 'benchmark': Invalid repo_id: model, must be of format namespace/name
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/dist-packages/evalscope/perf/utils/handler.py", line 17, in async_wrapper
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/evalscope/perf/benchmark.py", line 184, in benchmark
    api_plugin = api_plugin_class(args)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/evalscope/perf/plugin/api/openai_api.py", line 28, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(param.tokenizer_path)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/modelscope/utils/hf_util/patcher.py", line 280, in from_pretrained
    model_dir = get_model_dir(pretrained_model_name_or_path,
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/modelscope/utils/hf_util/patcher.py", line 161, in get_model_dir
    model_dir = snapshot_download(
                ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/modelscope/hub/snapshot_download.py", line 132, in snapshot_download
    return _snapshot_download(
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/modelscope/hub/snapshot_download.py", line 300, in _snapshot_download
    endpoint = _api.get_endpoint_for_read(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/modelscope/hub/api.py", line 423, in get_endpoint_for_read
    if not self.repo_exists(
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/modelscope/hub/api.py", line 567, in repo_exists
    raise Exception('Invalid repo_id: %s, must be of format namespace/name' % repo_type)
Exception: Invalid repo_id: model, must be of format namespace/name
